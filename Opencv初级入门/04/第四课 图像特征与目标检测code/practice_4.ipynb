{
 "cells": [
  {
   "cell_type": "raw",
   "id": "13fa465e",
   "metadata": {},
   "source": [
    "1、HOG特征提取\n",
    "统计计算图像局部的梯度方向直方图构建特征，与SVM结合广泛应用于图像识别中，在行人检测中获得极大的成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21df397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、灰度化（将图像看做一个x,y,z（灰度）的三维图像）；\n",
    "# 2、 采用Gamma校正法对输入图像进行颜色空间的标准化（归一化）；；\n",
    "# 3、 计算图像每个像素的梯度（包括大小和方向）；\n",
    "# 4、 将图像划分成小cells；\n",
    "# 5、 统计每个cell的梯度直方图（不同梯度的个数），得到cell的描述子；\n",
    "# 6、 将每几个cell组成一个block，得到block的描述子；\n",
    "# 7、 将图像image内的所有block的HOG特征descriptor串联起来就可以得到HOG特征，该特\n",
    "# 8、征向量就是用来目标检测或分类的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deade342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[322 123  92 184]\n",
      " [ 97 109  92 184]\n",
      " [228 106  94 188]\n",
      " [157 143  89 178]]\n",
      "[1.65200859 2.16342618 1.38857961 1.30450152]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#判断矩形i是否包含矩形o\n",
    "def is_inside(o,i):\n",
    "    ox,oy,ow,oh=o\n",
    "    ix,iy,iw,ih=i\n",
    "    return ox > ix and oy > iy and ox + ow < ix + iw and oy + oh < iy + ih\n",
    "#绘画人体颜色框\n",
    "def draw_person(image,person):\n",
    "    x,y,w,h=person\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "img=cv2.imread(\"people.jpg\")  \n",
    "hog = cv2.HOGDescriptor()  # 启动检测器对象\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())  # 指定检测器类型为人体\n",
    "found, w = hog.detectMultiScale(img,0.1,(2,2)) # 加载并检测图像\n",
    "print(found)\n",
    "print(w)\n",
    "#丢弃冗余矩形\n",
    "found_filtered = []\n",
    "for ri, r in enumerate(found):\n",
    "    for qi, q in enumerate(found):\n",
    "        if ri != qi and is_inside(r, q):\n",
    "            break\n",
    "    else:\n",
    "        found_filtered.append(r)\n",
    "#对有效矩形进行框定\n",
    "for person in found_filtered:\n",
    "    draw_person(img, person)\n",
    "cv2.imshow(\"people detection\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee62c75e",
   "metadata": {},
   "source": [
    "2、Harris角点检测\n",
    "在现实世界中，角点对应物体的拐角，道路的十字路口等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02394387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、计算图像在X和Y方向的梯度；\n",
    "# 2、计算图像两个方向梯度的乘积，IxIx,IyIy,IxIy；\n",
    "# 3、使用高斯函数对三者进行高斯加权，生成矩阵M的A,B,C；\n",
    "# 4、计算每个像素的Harris响应值R，并对小于某一阈值t的R置为零；\n",
    "# 5、在3×3或5×5的邻域内进行非最大值抑制，局部最大值点即为图像中的角点；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb7af008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "533091900.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "filename = 'harris2.png'\n",
    "img = cv2.imread(filename)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "\n",
    "# 输入图像必须是 float32 ,最后一个参数在 0.04 到 0.06 之间\n",
    "dst = cv2.cornerHarris(gray,2,3,0.06)\n",
    "\n",
    "#结果进行膨胀，可有可无\n",
    "dst = cv2.dilate(dst,None)\n",
    "print(dst)\n",
    "# 设定阈值，不同图像阈值不同\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "print(dst.max())\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.imshow('dst_img',img)\n",
    "#cv2.imshow('dst',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3021972",
   "metadata": {},
   "source": [
    "3、SIFT算法\n",
    "尺度不变特征变换算法(Scale-invariant feature transform，SIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aed04d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、尺度空间极值检测点检测\n",
    "# 2、关键点定位：去除一些不好的特征点，保存下来的特征点能够满足稳定性等条件\n",
    "# 3、关键点方向参数：获取关键点所在尺度空间的邻域，然后计算该区域的梯度和方向，根据计算得到的结果创建方向直方图，直方图的峰值为主方向的参数\n",
    "# 4、关键点描述符：每个关键点用一组向量（位置、尺度、方向）将这个关键点描述出来，使其不随着光照、视角等等影响而改变\n",
    "# 5、关键点匹配：分别对模板图和实时图建立关键点描述符集合，通过对比关键点描述符来判断两个关键点是否相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6937624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img=cv2.imread('harris2.png')\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "shift=cv2.SIFT_create()\n",
    "kp=shift.detect(gray,None)\n",
    "img=cv2.drawKeypoints(gray,kp,img)\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84697e38",
   "metadata": {},
   "source": [
    "4、LBP纹理特征\n",
    "用来描述图像局部纹理特征的算子；它具有旋转不变性和灰度不变性等显著的优点\n",
    "LBP算子定义在一个3×33×3的窗口内，以窗口中心像素为阈值，与相邻的8个像素的灰度值比较，若周围的像素值大于中心像素值，则该位置被标记为1;，否则标记为0。如此可以得到一个8位二进制数，将这个值作为窗口中心像素点的LBP值，以此来反应这个3×3区域的纹理信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ee540c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 500)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def LBP(src):\n",
    "    '''\n",
    "    :param src:灰度图像\n",
    "    :return:\n",
    "    '''\n",
    "    height = src.shape[0]\n",
    "    width = src.shape[1]\n",
    "    dst = src.copy()\n",
    "    lbp_value = np.zeros((1,8), dtype=np.uint8)\n",
    "    #print(lbp_value)\n",
    "    neighbours = np.zeros((1,8), dtype=np.uint8)\n",
    "    #print(neighbours)\n",
    "    for x in range(1, width-1):\n",
    "        for y in range(1, height-1):\n",
    "            neighbours[0, 0] = src[y - 1, x - 1]\n",
    "            neighbours[0, 1] = src[y - 1, x]\n",
    "            neighbours[0, 2] = src[y - 1, x + 1]\n",
    "            neighbours[0, 3] = src[y, x - 1]\n",
    "            neighbours[0, 4] = src[y, x + 1]\n",
    "            neighbours[0, 5] = src[y + 1, x - 1]\n",
    "            neighbours[0, 6] = src[y + 1, x]\n",
    "            neighbours[0, 7] = src[y + 1, x + 1]\n",
    "            center = src[y, x]\n",
    "            for i in range(8):\n",
    "                if neighbours[0, i] > center:\n",
    "                    lbp_value[0, i] = 1\n",
    "                else:\n",
    "                    lbp_value[0, i] = 0\n",
    "\n",
    "            lbp = lbp_value[0, 0] * 1 + lbp_value[0, 1] * 2 + lbp_value[0, 2] * 4 + lbp_value[0, 3] * 8 \\\n",
    "                + lbp_value[0, 4] * 16 + lbp_value[0, 5] * 32 + lbp_value[0, 6] * 64 + lbp_value[0, 7] * 128\n",
    "            \n",
    "            #print(lbp)\n",
    "            dst[y, x] = lbp\n",
    "\n",
    "    return dst\n",
    "\n",
    "img = cv2.imread('people.jpg',0)\n",
    "print(img.shape)\n",
    "cv2.imshow('src',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "new_img = LBP(img)\n",
    "\n",
    "cv2.imshow('dst',new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f48a3d92",
   "metadata": {},
   "source": [
    "5、模板匹配\n",
    "从左到右，从上到下，计算模板与重叠子图的匹配度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4abd6b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 92, 3)\n",
      "(643, 903, 3)\n",
      "0.313273549079895 1.0 (164, 186) (61, 0)\n",
      "0.39695343375205994 0.8127202391624451 (232, 111) (164, 186)\n",
      "-0.3538476526737213 0.5110524296760559 (356, 64) (164, 186)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\22967\\AppData\\Local\\Temp/ipykernel_9212/4273129370.py:20: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  cv2.namedWindow(\"match-\" + np.str(md), cv2.WINDOW_NORMAL)\n",
      "C:\\Users\\22967\\AppData\\Local\\Temp/ipykernel_9212/4273129370.py:21: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  cv2.imshow(\"match-\" + np.str(md), target)\n"
     ]
    }
   ],
   "source": [
    "#模板匹配\n",
    "import cv2\n",
    "import numpy as np\n",
    "def template_demo(tpl,target):\n",
    "\n",
    "    methods = [cv2.TM_SQDIFF_NORMED, cv2.TM_CCORR_NORMED, cv2.TM_CCOEFF_NORMED]   #3种模板匹配方法\n",
    "    th, tw = tpl.shape[:2]\n",
    "    for md in methods:\n",
    "        #print(md)\n",
    "        result = cv2.matchTemplate(target, tpl, md)\n",
    "        #print(result.shape)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        print(min_val, max_val, min_loc, max_loc)\n",
    "        if md == cv2.TM_SQDIFF_NORMED:\n",
    "            tl = min_loc\n",
    "        else:\n",
    "            tl = max_loc\n",
    "        br = (tl[0]+tw, tl[1]+th)   #br是矩形右下角的点的坐标\n",
    "        cv2.rectangle(target, tl, br, (0, 0, 255), 2)\n",
    "        cv2.namedWindow(\"match-\" + np.str(md), cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"match-\" + np.str(md), target)\n",
    "        \n",
    "tpl =cv2.imread(\"sample2.jpg\")\n",
    "print(tpl.shape)\n",
    "target = cv2.imread(\"target1.jpg\")\n",
    "print(target.shape)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.namedWindow('template image', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"template image\", tpl)\n",
    "cv2.namedWindow('target image', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"target image\", target)\n",
    "template_demo(tpl,target)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e10f77a",
   "metadata": {},
   "source": [
    "6、人脸检测1\n",
    "一般包括四个流程：人脸检测、人脸对齐、人脸特征提取、人脸识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67784449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face : 1\n",
      "[[ 68  35 249 249]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 读入图像\n",
    "img = cv2.imread(\"3.png\")\n",
    "\n",
    "# 加载人脸特征，该文件在 python安装目录\\Lib\\site-packages\\cv2\\data 下\n",
    "face_cascade = cv2.CascadeClassifier(r'haarcascade_frontalface_default.xml')\n",
    "# 将读取的图像转为COLOR_BGR2GRAY，减少计算强度\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 检测出的人脸个数\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor = 1.15, minNeighbors = 4, minSize = (5, 5))\n",
    "\n",
    "print(\"Face : {0}\".format(len(faces)))\n",
    "print(faces)\n",
    "# 用矩形圈出人脸的位置\n",
    "for(x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2) \n",
    "\n",
    "cv2.namedWindow(\"Faces\")\n",
    "cv2.imshow(\"Faces\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06f8104c",
   "metadata": {},
   "source": [
    "7、人脸检测2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c0cd3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(90, 66) (305, 281)]\n",
      "[[ 95 137]\n",
      " [ 98 162]\n",
      " [104 187]\n",
      " [108 212]\n",
      " [117 235]\n",
      " [131 255]\n",
      " [149 272]\n",
      " [170 285]\n",
      " [192 289]\n",
      " [215 285]\n",
      " [235 270]\n",
      " [253 251]\n",
      " [266 229]\n",
      " [272 205]\n",
      " [276 180]\n",
      " [283 156]\n",
      " [285 131]\n",
      " [101 114]\n",
      " [116 106]\n",
      " [134 107]\n",
      " [153 110]\n",
      " [172 117]\n",
      " [209 117]\n",
      " [227 109]\n",
      " [246 106]\n",
      " [265 105]\n",
      " [282 113]\n",
      " [190 135]\n",
      " [191 153]\n",
      " [191 172]\n",
      " [192 189]\n",
      " [177 199]\n",
      " [184 203]\n",
      " [192 205]\n",
      " [201 203]\n",
      " [208 199]\n",
      " [125 135]\n",
      " [136 127]\n",
      " [151 127]\n",
      " [163 139]\n",
      " [149 143]\n",
      " [135 143]\n",
      " [219 138]\n",
      " [230 127]\n",
      " [245 126]\n",
      " [257 134]\n",
      " [247 142]\n",
      " [232 142]\n",
      " [161 235]\n",
      " [172 226]\n",
      " [185 219]\n",
      " [193 222]\n",
      " [200 219]\n",
      " [212 226]\n",
      " [224 235]\n",
      " [213 247]\n",
      " [201 252]\n",
      " [193 252]\n",
      " [184 252]\n",
      " [172 247]\n",
      " [168 235]\n",
      " [185 231]\n",
      " [193 232]\n",
      " [200 232]\n",
      " [217 235]\n",
      " [201 235]\n",
      " [193 236]\n",
      " [185 235]] <class 'numpy.matrix'>\n"
     ]
    }
   ],
   "source": [
    "# -*- coding：utf-8 -*-\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "predictor_model = './shape_predictor_68_face_landmarks/shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_model)\n",
    "\n",
    "# cv2读取图像\n",
    "test_film_path = \"./3.png\"\n",
    "img = cv2.imread(test_film_path)\n",
    "# 取灰度\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# 人脸数rects\n",
    "rects = detector(img_gray, 0)\n",
    "print(rects[0])\n",
    "for i in range(len(rects)):\n",
    "    landmarks = np.matrix([[p.x, p.y] for p in predictor(img,rects[i]).parts()])\n",
    "    print(landmarks, type(landmarks))\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        # 68点的坐标\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        #print(idx+1, pos)\n",
    "\n",
    "        # 利用cv2.circle给每个特征点画一个圈，共68个\n",
    "        cv2.circle(img, pos, 3, color=(0, 255, 0))\n",
    "        # 利用cv2.putText输出1-68\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img,str(idx+1),pos,font,0.5,(0, 0, 255),1,cv2.LINE_AA)\n",
    "#         cv2.putText(img, str(idx+1), (123,456), font, 2, (0,255,0), 3)\n",
    "#cv2.imwrite(\"result.png\", img)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a94d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
